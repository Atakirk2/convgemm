/**Convolution DNN Evaluator
 * 
 * This evaluator measures the performance obtained by the  3 algorithms compared 
 * to solve convolutions into CNN convolutional layers. The evaluator compares a naive 
 * convolution against the im2col + GEMM approach against our mplicit im2col gemm (gemm_conv) 
 * algorithm. 
 * The evaluator admits a compilation parameter to omit the execution of the naive
 * convolution (-DNONAIVE).
 * The evaluator also has two evaluation modes that can be chosen at compile time:
 *  -Model evaluation(default): Times the execution of the whole CNN model.
 *  -Layer evaluation(-DLAYER_EVAL): Times each layer and then agregates the results.
 * 
 * This source also contains a precision evaluator which compares the  performance obtained
 * by the convgemm algorithm using fp16 and fp32 precision (-Deval_precision).
 * 
 * The evaluator suports two output modes:
 *     - Human readable(default): Custom format easy to read and interpret.
 *     - CSV (-Dout_csv): CSV format delimited with semicolons(;).
 * 
 * The models used by this evaluator had been pruned to only contain the convolutional 
 * layers of the corresponding CNN.
 * The evaluation was developed and tested for ARMCortex  A-57 and NVIDIA Carmel
 * 
 * @author P. San Juan
 * @date 04/2020
 */
#include <unistd.h>
#include <stdio.h>
#include <stdlib.h>
#include "convGemm.h"
#include "convCommon.h"
#ifdef PWR
#include "pmlib.h"
#endif

#define CONV 0
#define IM2COL_GEMM 1
#define GEMM 2
#define CONVGEMM 3

#ifdef i_16
    #define dType int16_t
    #define EPS 5e-4
    #define B_MC hBLOCK_MC
    #define B_NC hBLOCK_NC
    #define B_KC hBLOCK_KC
#else
    #define dType _Float16
    #define EPS 5e-4
    #define B_MC hBLOCK_MC
    #define B_NC hBLOCK_NC
    #define B_KC hBLOCK_KC
#endif

//typedef dualBuffer;
struct dualBufferS{
    float * buff;
    struct dualBufferS* partner; 
};

struct dualBuffer{
    dType * buff;
    struct dualBuffer* partner; 
};



/** Computes the maximum matrix sizes for a model.
 * 
 * Computes the sizes of all matrices for each layer of the model using the model
 * parameters and returns the maximum size for each type of matrix.
 * 
 * @param[in] model CNN model parameters.
 * @param[in] nL Number of layers of the model.
 * @param[in] maxBatch Maximum batch size.
 * @param[out] masSizeF Maximum size of Filters matrix
 * @param[out] maxSizeIn Maximum size of input tensor.
 * @param[out] maxSizeOut Maximum size of the output matrix from the convolution.
 * @param[out] maxSizeAux Maximum size of the auxiliar matrix generated by aplying the im2col transform to the input tensor.
 */
void maxMatrixSizes(int** model,const int nL, const int maxBatch, int* maxSizeF, int* maxSizeIn, int* maxSizeOut, int* maxSizeAux)
{
    int l,
    sizeF,sizeIn, sizeOut, sizeAux, ho, wo;
    
    *maxSizeF = 0; *maxSizeIn = 0; *maxSizeOut = 0;
    
    for(l=0; l < nL; l++)
    {
		//sizeF = kn* kh *kw*c  
        sizeF = model[l][6] * model[l][4] * model[l][5] * model[l][3];
		//sizeIn = h* w* c * b
        sizeIn = model[l][1] * model[l][2] * model[l][3] * maxBatch;
		
		//ho = floor((h - kh + 2 * pad) / stride + 1);
		ho = floor((model[l][1] - model[l][4] + 2 * model[l][8]) / model[l][7] + 1);
        //wo = floor((w - kw + 2 * pad) / stride + 1);
        wo = floor((model[l][2] - model[l][5] + 2 * model[l][8]) / model[l][7] + 1);
		//sizeOut = ho * wo *kn * b
        sizeOut = ho * wo * model[l][6] * maxBatch;
		//sizeAux = c*kh*kw *ho*wo*b
		sizeAux = model[l][3] * model[l][4] * model[l][5] * ho * wo * maxBatch;
        *maxSizeF = sizeF > *maxSizeF? sizeF: *maxSizeF;
        *maxSizeIn = sizeIn > *maxSizeIn? sizeIn: *maxSizeIn;
        *maxSizeOut = sizeOut  > *maxSizeOut? sizeOut: *maxSizeOut;
		*maxSizeAux = sizeAux  > *maxSizeAux? sizeAux: *maxSizeAux;
    }
    
}


/** Timing of a CNN model.
 * 
 * Executes and times a given model for a given batch size using the selected algorithm.
 * This function was developed to avoid unnecesary code replication.
 * 
 * @param[in] algorithm Algorithm to evaluate [CONV, IM2COL_GEMM, GEMM, or CONVGEMM].
 * @param[in] model CNN model parameters.
 * @param[in] nL Number of layers of the model.
 * @param[in] repe NUmber of repetitions for timing smoothing.
 * @param[in] b Batch size.
 * @param[in] j Index to adress the corresponding batch size positions in the timer matrix.
 * @param[in] F Filter matrix.
 * @param[in] inOut Dual buffer for input/output in each layer convolution.
 * @param[in] Ac_pack  Workspace buffer for the packing of Ac.
 * @param[in] Bc_pack Workspace buffer for the packing od Bc.
 * @param[in] Aux Workspace buffer to hold the intermediate matrix generated by the im2col transform.
 * @param[in,out] timer Matrix containing the timing results for each batch size for the given algorithm.
 */
void inline timeNet(const int algorithm, int ** model, const int nL, const int repe, const int b, const int j,  float* F, struct dualBufferS* inOut,  float* Ac_pack,  float* Bc_pack,  float* Aux,  double* timer)
{
    double tIni;
    int r,l; //loop indexes 
    int h, w, c, kh, kw, kn, stride, pad, ho, wo;//convolution parameters
    float ONE=1, ZERO=0;
    
//Evaluating algorithm
#ifndef LAYER_EVAL 
        tIni = bli_clock();
        for(r = 0; r < repe; r++)
#endif
            for(l=0; l < nL; l++)
            {
                h = model[l][1]; w = model[l][2]; c = model[l][3];
                kh = model[l][4]; kw = model[l][5]; kn = model[l][6];
                stride = model[l][7]; pad = model[l][8];
                ho = floor((h - kh + 2 * pad) / stride + 1);
                wo = floor((w - kw + 2 * pad) / stride + 1);
                
#ifdef LAYER_EVAL
                tIni = bli_clock();
                for(r = 0; r < repe; r++)
#endif          
                    switch(algorithm)
                    {
                        case CONV:
                            convolutionNaive(h,w,c,b,inOut->buff,kh,kw,kn,F,inOut->partner->buff, stride);
                            inOut = inOut->partner;
                            break;
                        case IM2COL_GEMM:
                            im2Col(h,w,c,b,inOut->buff,kh,kw, stride,Aux);
                        case GEMM:
                            //bli_sgemm(BLIS_NO_TRANSPOSE,BLIS_NO_TRANSPOSE,kn,ho*wo*b,kh*kw*c,&ONE,F,1,kn,Aux,1,kh*kw*c,&ZERO,inOut->partner->buff,1,kn);
                            sgemm_cust(kn,ho*wo*b,kh*kw*c,1,F,kn,Aux,kh*kw*c,0,inOut->partner->buff,kn,Ac_pack,Bc_pack);
                            inOut = inOut->partner;
                            break;
                        case CONVGEMM:
                            sconvGemm(kh,kw,c,kn,1,F, h,w,b, stride, stride, inOut->buff, 0,inOut->partner->buff,Ac_pack,Bc_pack);
                            inOut = inOut->partner;
                            break;
                    }
#ifdef LAYER_EVAL
                timer[l+j*(nL+2)] = bli_clock() -tIni;
#endif
                
                //bli_scopyv(BLIS_NO_CONJUGATE,kn*ho*wo*b,Out,1,Aux,1);//Copy to force cache clearing
            }
#ifndef LAYER_EVAL                 
        timer[nL+j*(nL+2)] = bli_clock() -tIni;
#endif
    
}



/** Performs a convolution evaluation of a DNN model.
 * 
 * Evaluates all the layers on the model for each convolution algorithm tested
 * and computes the timing measures.
 * 
 * @param[in] model CNN model parameters.
 * @param[in] nL Number of layers of the model.
 * @param[in] minBatch Minimum batch size to evaluate.
 * @param[in] maxBatch Max batch size to evaluate.
 * @param[in] stepBatch Step for the batch size range.
 * @param[in] repe Number of repetitios for timing smoothing.
 * @return Matrix stack containing all the timing measurments( timing_measures * (nL * numbatch)).
 */
double ** evalNet(int** model, const int nL, const int minBatch, const int maxBatch, const int stepBatch, const int repe)
{
    double **times, tIni, *tConv, *tIm2Col, *tGemm, *tIm2ColGemm, *tImp; //Timing vectors
    double sum;
    int i, j,r,l, b, //loop indexes
     	maxSizeF, maxSizeIn, maxSizeOut, maxSizeAux;//matrixz max sizes
    int numBatch, timers=5;
    float *F, *Ac_pack, *Bc_pack, *Aux;
    struct dualBufferS inOut;
    
	
	printf("Starting evaluation\n");
    
    //Allocating matrices
    maxMatrixSizes(model, nL, maxBatch, &maxSizeF, &maxSizeIn,&maxSizeOut, &maxSizeAux);

    //Input and output matrices
    F = (float*) malloc(maxSizeF * sizeof(float));
    inOut.buff = (float*) malloc(max(maxSizeOut,maxSizeIn) * sizeof(float));
    inOut.partner = (struct dualBufferS *) malloc(sizeof(struct dualBufferS));
    inOut.partner->buff = (float*) malloc(max(maxSizeOut,maxSizeIn) * sizeof(float));
    inOut.partner->partner = &inOut;
    if(F == NULL || inOut.buff == NULL || inOut.partner->buff == NULL)
    {
        perror("Error allocating matrices:");
        exit(2);
    }
    //auxiliar matrices
    Ac_pack = (float*) aligned_alloc(4096,BLOCK_MC*BLOCK_KC*sizeof(float));
    Bc_pack = (float*) aligned_alloc(4096,BLOCK_KC*BLOCK_NC*sizeof(float));
    Aux = (float*) malloc(maxSizeAux * sizeof(float));
    if(Aux == NULL || Ac_pack == NULL || Bc_pack == NULL)
    {
        perror("Error allocating auxiliar matrices:");
        exit(2);
    }
	
    bli_srandv(maxSizeF,F,1);
    bli_srandv(maxSizeIn,inOut.buff,1);

    
    numBatch = (maxBatch -minBatch)/stepBatch+1;
    //Allocating timing structure
	times = (double **) malloc (timers * sizeof(double*));
    tConv = (double *) calloc ((nL+2)*numBatch,sizeof(double));
	tIm2Col = (double *) calloc ((nL+2)*numBatch,sizeof(double));
    tGemm = (double *) calloc ((nL+2)*numBatch,sizeof(double));
	tIm2ColGemm= (double *) calloc ((nL+2)*numBatch,sizeof(double));
	tImp= (double *) calloc ((nL+2)*numBatch,sizeof(double));
    if(tConv == NULL || tIm2Col == NULL || tIm2ColGemm == NULL || tImp == NULL)
    {
        perror("Error allocating timing structures:");
        exit(2);
    }
    times[0] = tConv;
	times[1] = tIm2Col;
    times[2] = tGemm;
	times[3] = tIm2ColGemm;
	times[4] = tImp;

    
    for(b=minBatch,j=0;b<=maxBatch; b+=stepBatch,j++)
    {
        printf("Evaluation with batch=%d\n",b);

#ifndef NONAIVE  
        timeNet(CONV, model, nL, repe, b, j, F, &inOut, Ac_pack, Bc_pack, Aux,  tConv);
#endif
        timeNet(GEMM, model, nL, repe, b, j, F,  &inOut, Ac_pack, Bc_pack, Aux,  tGemm);
        
        timeNet(IM2COL_GEMM, model, nL, repe, b, j, F, &inOut, Ac_pack, Bc_pack, Aux,  tIm2ColGemm);
        
        timeNet(CONVGEMM, model, nL, repe, b, j, F, &inOut, Ac_pack, Bc_pack, Aux,  tImp);
        

#ifdef LAYER_EVAL   
		//Timing averaging and statistics
        for(l=0; l < nL;l++)
        {
            tIm2Col[l+j*(nL+2)] =  tIm2ColGemm[l+j*(nL+2)] -  tGemm[l+j*(nL+2)];//Compute im2col times
            for(i = 0; i < timers; i++)
                times[i][l+j*(nL+2)] /= repe;
        }

        for(i = 0; i < timers; i++)
        {
            bli_dasumv(nL,&times[i][j*(nL+2)],1,&sum);
            times[i][nL+j*(nL+2)] = sum;
            times[i][nL+1+j*(nL+2)]= sum/nL;
        }
#else
        tIm2Col[nL+j*(nL+2)] =  tIm2ColGemm[nL+j*(nL+2)] -  tGemm[nL+j*(nL+2)]; //Compute im2col time
        for(i = 0; i < timers; i++)
        {
            times[i][nL+j*(nL+2)] /= repe;
            times[i][nL+1+j*(nL+2)]= times[i][nL+j*(nL+2)]/nL;
        }
#endif
    }
    
    free(F);
    free(inOut.buff);
    free(inOut.partner->buff);
    free(inOut.partner);
    free(Ac_pack);
    free(Bc_pack);
    free(Aux);
    
    return times;
}

void irandm(unsigned int m, unsigned int n, dType *M,unsigned int ldm)
{
    int i,j;
    
    for ( j=0; j<n; j++ )
        for ( i=0; i<m; i++ )
            M[i+j*ldm] = rand() % 32767;
}

/** Performs a convolution evaluation of a DNN model with FP32 and FP16 precisions.
 * 
 * Evaluates all the layers on the model using the convgemm algorithm for single and half precision
 * and computes the timing measures.
 * 
 * @param[in] model CNN model parameters.
 * @param[in] nL Number of layers of the model.
 * @param[in] minBatch Minimum batch size to evaluate.
 * @param[in] maxBatch Max batch size to evaluate.
 * @param[in] stepBatch Step for the batch size range.
 * @param[in] repe Number of repetitios for timing smoothing.
 * @return Matrix containing all the timing measurments( 2 * numbatch).
 */
#ifdef PWR
double ** evalNet_precision(int** model, const int nL, const int minBatch, const int maxBatch, const int stepBatch, const int repe, counter_t* pwrCounter)
#else
double ** evalNet_precision(int** model, const int nL, const int minBatch, const int maxBatch, const int stepBatch, const int repe)
#endif
{
    double **times, tIni, *tdType, *tSingle; //Timing vectors
    double sum;
    int i, j,r,l, b, //loop indexes
     	maxSizeF, maxSizeIn, maxSizeOut, maxSizeAux;//matrixz max sizes
    int numBatch, timers=2;
    int h, w, c, kh, kw, kn, stride, pad, ho, wo;//convolution parameters
    float *F, *Ac_pack, *Bc_pack;
    dType *F2, *Ac_pack2, *Bc_pack2;
    struct dualBufferS inOut, *piO; //Double buffer, and pointer for navigation
    struct dualBuffer inOut2, *hpiO; //Multy type Double buffer, and pointer for navigation
    
	
	printf("Starting evaluation\n");
    
    //Allocating matrices
    maxMatrixSizes(model, nL, maxBatch, &maxSizeF, &maxSizeIn,&maxSizeOut, &maxSizeAux);

    //Input and output matrices
    F = (float*) malloc(maxSizeF * sizeof(float));
    inOut.buff = (float*) malloc(max(maxSizeOut,maxSizeIn) * sizeof(float));
    inOut.partner = (struct dualBufferS *) malloc(sizeof(struct dualBufferS));
    inOut.partner->buff = (float*) malloc(max(maxSizeOut,maxSizeIn) * sizeof(float));
    inOut.partner->partner = &inOut;
    piO = &inOut;
    if(F == NULL || inOut.buff == NULL || inOut.partner->buff == NULL)
    {
        perror("Error allocating matrices:");
        exit(2);
    }
    //auxiliar matrices
    Ac_pack = (float*) aligned_alloc(4096,BLOCK_MC*BLOCK_KC*sizeof(float));
    Bc_pack = (float*) aligned_alloc(4096,BLOCK_KC*BLOCK_NC*sizeof(float));
    if(Ac_pack == NULL || Bc_pack == NULL)
    {
        perror("Error allocating auxiliar matrices:");
        exit(2);
    }
    
    //Input and output matrices (half precision)
    F2 = (dType*) malloc(maxSizeF * sizeof(dType));
    inOut2.buff = (dType*) malloc(max(maxSizeOut,maxSizeIn) * sizeof(dType));
    inOut2.partner = (struct dualBuffer *) malloc(sizeof(struct dualBuffer));
    inOut2.partner->buff = (dType*) malloc(max(maxSizeOut,maxSizeIn) * sizeof(dType));
    inOut2.partner->partner = &inOut2;
    hpiO = &inOut2;
    if(F2 == NULL || inOut2.buff == NULL || inOut2.partner->buff == NULL)
    {
        perror("Error allocating matrices:");
        exit(2);
    }
    //auxiliar matrices
    Ac_pack2 = (dType*) aligned_alloc(4096,B_MC*B_KC*sizeof(dType));
    Bc_pack2 = (dType*) aligned_alloc(4096,B_KC*B_NC*sizeof(dType));
    if(Ac_pack2 == NULL || Bc_pack2 == NULL)
    {
        perror("Error allocating auxiliar matrices:");
        exit(2);
    }
	
    bli_srandv(maxSizeF,F,1);
    bli_srandv(maxSizeIn,inOut.buff,1);
#ifdef i_16
    irandm( maxSizeF, 1, F2, 1 );
    irandm( maxSizeIn, 1, inOut2.buff, 1 );
#else
    decreasePrecissionV_SH(maxSizeF,F,F2);
    decreasePrecissionV_SH(maxSizeIn,inOut.buff,inOut2.buff);
#endif

    
    numBatch = (maxBatch -minBatch)/stepBatch+1;
    //Allocating timing structure
	times = (double **) malloc (timers * sizeof(double*));
    tdType = (double *) calloc (numBatch,sizeof(double));
	tSingle = (double *) calloc (numBatch,sizeof(double));
    if(tSingle == NULL || tdType == NULL)
    {
        perror("Error allocating timing structures:");
        exit(2);
    }
	times[0] = tSingle;
    times[1] = tdType;


    #ifdef PWR 
    pm_start_counter(pwrCounter);
    #endif 
    for(b=minBatch,j=0;b<=maxBatch; b+=stepBatch,j++)
    {
        printf("Evaluation with batch=%d\n",b);

        //Evaluating single precision convGemm
        tIni = bli_clock();
        for(r = 0; r < repe; r++)
            for(l=0; l < nL; l++)
            {
                h = model[l][1]; w = model[l][2]; c = model[l][3];
                kh = model[l][4]; kw = model[l][5]; kn = model[l][6];
                stride = model[l][7]; pad = model[l][8];
                ho = floor((h - kh + 2 * pad) / stride + 1);
                wo = floor((w - kw + 2 * pad) / stride + 1);

                sconvGemm(kh,kw,c,kn,1,F, ho,wo,b, stride, stride, piO->buff, 0,piO->partner->buff,Ac_pack,Bc_pack);
                piO = piO->partner;

                
            }              
        tSingle[j] = (bli_clock() -tIni )/repe;
        #ifdef PWR 
        pm_stop_counter(pwrCounter);
        #endif   
        
        //Evaluating dType precision convGemm
        #ifdef PWR 
        pm_continue_counter(pwrCounter);
        #endif 
        tIni = bli_clock();
        for(r = 0; r < repe; r++)
            for(l=0; l < nL; l++)
            {
                h = model[l][1]; w = model[l][2]; c = model[l][3];
                kh = model[l][4]; kw = model[l][5]; kn = model[l][6];
                stride = model[l][7]; pad = model[l][8];
                ho = floor((h - kh + 2 * pad) / stride + 1);
                wo = floor((w - kw + 2 * pad) / stride + 1);

#ifdef i_16
                i16gemm_conv(kh,kw,c,kn,1,F2, ho,wo,b, stride, hpiO->buff, 0,hpiO->partner->buff,Ac_pack2,Bc_pack2);
                hpiO = hpiO->partner;
#else
                hconvGemm(kh,kw,c,kn,1,F2, ho,wo,b, stride, hpiO->buff, 0,hpiO->partner->buff,Ac_pack2,Bc_pack2);
                hpiO = hpiO->partner;
#endif
            }              
        tdType[j] = (bli_clock() -tIni )/repe;
        #ifdef PWR 
        pm_stop_counter(pwrCounter);
        pm_continue_counter(pwrCounter);
        #endif 
        
    }
    #ifdef PWR 
    pm_stop_counter(pwrCounter);
    #endif   
    
    free(F);
    free(inOut.buff);
    free(inOut.partner->buff);
    free(inOut.partner);
    free(Ac_pack);
    free(Bc_pack);
    
    free(F2);
    free(inOut2.buff);
    free(inOut2.partner->buff);
    free(inOut2.partner);
    free(Ac_pack2);
    free(Bc_pack2);

    
    return times;
}

/** Loads model from file.
 * 
 * Loads model parameters from file and generates model structure. 
 * The model array generated contains an integer matrix of number_layers x 9.
 * 
 * @param[in] modelName Name of the file containing the model.
 * @param[out]  modelPtr Pointer to the model structure generated.
 * @return The number of layers of the model.
 */
int loadModel(const char* modelName, int *** modelPtr)
{
    int nL, l = 0, 
		filled;
    FILE* in;
    int **model;
	
        
    in = fopen(modelName,"r");
    if(in==NULL)
    {
        perror("Error opening model file:");
        exit(1);
    }
    
    filled = fscanf(in,"%*6c%d\n",&nL); //read number of layers
	if(filled !=1)
	{
		        perror("Error reading model file:");
				exit(1);
	}
	
    model = (int**) malloc(nL*sizeof(int*));//Alloc model structure
    
    filled = fscanf(in,"%*[^\n]\n");//skip descriptor line
    for(l=0; l < nL; l++)
    {
        model[l] = (int*) malloc(9 * sizeof(int)); //Alloc layer product dimensions
        //model = [id,h,w,c,kh,kw,kn,stride,pad]
		filled = fscanf(in,"%d;%d;%d;%d;%d;%d;%d;%d;%d#\n",&model[l][0],&model[l][1],&model[l][2],&model[l][3],&model[l][4],&model[l][5],&model[l][6],&model[l][7],&model[l][8]);
		if(filled !=9)
		{
			perror("Error reading layer:");
			exit(1);
		}
    }
    
    fclose(in);
    
    *modelPtr = model;
    
    printf("Model %s loaded[%d layers]\n",modelName,nL);
    
    return nL;
}


/** Prints evaluation results  to standard output.
 * 
 * Formats and prints the timing measures obtained by the evaluation. 
 * Furthermore it computes performance metrics in Gflops to enrich the 
 * presented results.
 * 
 * 
 * @param[in] nL Number of layers in the model.
 * @param[in] model CNN model parameters.
 * @param[in] perfMeasures Matrix containing the timing measures for each layer and each convolution method.
 * @param[in] minBatch Minimum batch size used in the evaluation.
 * @param[in] maxBatch Maximum batch sizeused in the evaluation.
 * @param[in] stepBatch Step for batch size used in the evaluation.
 * @param[in] repe NUmber of repetitions used to smooth the results.
 */
void genOutput(const int nL, int ** model, double** perfMeasures,const int minBatch, const int maxBatch, const int stepBatch,const int repe)
{
    int i, l,j,b;
	int id, h,w,c,kh,kw,kn,stride,pad,ho,wo;
	double gflop, gflopTotal;
	
	
    printf("Evaluation results (averaged results of %d repetitions):\n",repe);
    for(b=minBatch,j=0;b<=maxBatch; b+=stepBatch,j++)
    {
        printf("Batch=%d \n",b);
		gflopTotal=0;
		printf("layer \t Naive    \t im2col    \t gemm    \t GflopsGemm    \t im2colgemm   \t GflopsIm2ColGemm  \t implicitGemm  \t GflopsImplicit\n");

        for (l = 0;l < nL; l++)
		{
				id = model[l][0];
				h = model[l][1]; w = model[l][2]; c = model[l][3];
				kh = model[l][4]; kw = model[l][5]; kn = model[l][6];
				stride = model[l][7]; pad = model[l][8];
				ho = floor((h - kh + 2 * pad) / stride + 1);
				wo = floor((w - kw + 2 * pad) / stride + 1);
				
				gflop = ( 2.0 * kn*ho*wo*b*kh*kw*c ) /  1.0e9 ;
				gflopTotal+=gflop;
#ifdef LAYER_EVAL  
				printf("%d    \t %.4g    \t %.4g    \t %.4g    \t %.5g    \t %.4g  \t %.5g         \t %.4g    \t %.5g\n",
				       id,perfMeasures[0][l+j*(nL+2)],perfMeasures[1][l+j*(nL+2)],
					   perfMeasures[2][l+j*(nL+2)], gflop / perfMeasures[2][l+j*(nL+2)],
                       perfMeasures[3][l+j*(nL+2)], gflop/perfMeasures[3][l+j*(nL+2)],
					   perfMeasures[4][l+j*(nL+2)], gflop/perfMeasures[4][l+j*(nL+2)]);
#endif	
			
		}

	
		printf("Tot \t %.4g    \t %.4g    \t %.4g    \t %.5g    \t %.4g  \t %.5g           \t %.4g    \t %.5g\n",
				       perfMeasures[0][l+j*(nL+2)],perfMeasures[1][l+j*(nL+2)],
					   perfMeasures[2][l+j*(nL+2)], gflopTotal / perfMeasures[2][l+j*(nL+2)],
                       perfMeasures[3][l+j*(nL+2)], gflopTotal /perfMeasures[3][l+j*(nL+2)],
					   perfMeasures[4][l+j*(nL+2)], gflopTotal /perfMeasures[4][l+j*(nL+2)]);
		l++;
		printf("Avg \t %.4g    \t %.4g    \t %.4g    \t %.5g    \t %.4g   \t %.5g          \t %.4g    \t %.5g\n",
				       perfMeasures[0][l+j*(nL+2)],perfMeasures[1][l+j*(nL+2)],
					   perfMeasures[2][l+j*(nL+2)], (gflopTotal/nL) / perfMeasures[2][l+j*(nL+2)],
                       perfMeasures[3][l+j*(nL+2)], (gflopTotal/nL) /perfMeasures[3][l+j*(nL+2)],
					   perfMeasures[4][l+j*(nL+2)], (gflopTotal/nL) /perfMeasures[4][l+j*(nL+2)]);
    }
    
}


#ifdef PWR
int get_energy_stats(counter_t pm_counter, int set, double* avgPwr, double* maxPwr, double * energy){


	int	i;
	int	ini, fin, watts_size;
	double time, sum=0, currMax = 0;
	

	if ( pm_counter.aggregate )//this function only wotks with aggregate counters
	{	

		if (set > pm_counter.measures->energy.watts_sets_size-1 || set <0)
			return -1;

			ini=pm_counter.measures->energy.watts_sets[set];
			fin=pm_counter.measures->energy.watts_sets[set+1];
	
			watts_size=pm_counter.measures->energy.watts_size;
			time=pm_counter.measures->timing[(set*2)+1]-pm_counter.measures->timing[set*2];
	
			for(i=ini; i<fin; i++)
			{
				currMax = pm_counter.measures->energy.watts[i] > currMax? pm_counter.measures->energy.watts[i]:currMax;
                sum+= pm_counter.measures->energy.watts[i];
			}
			sum/=(fin-ini);
		
        /*      printf("Time:       %f s\n", time);
                printf("Avg. power: %f W\n", sum);
                printf("Energy:     %f Ws\n", sum*time);
	*/
                *avgPwr = sum;
                *maxPwr = currMax;
                *energy = *avgPwr * time;
	}
	else
    {
        return -1;
    }
}
#endif


/** Prints evaluation results  to standard output.
 * 
 * Formats and prints the timing measures obtained by the evaluation. 
 * Furthermore it computes performance metrics in Gflops to enrich the 
 * presented results.
 * 
 * 
 * @param[in] nL Number of layers in the model.
 * @param[in] model CNN model parameters.
 * @param[in] perfMeasures Matrix containing the timing measures for each layer and each convolution method.
 * @param[in] minBatch Minimum batch size used in the evaluation.
 * @param[in] maxBatch Maximum batch sizeused in the evaluation.
 * @param[in] stepBatch Step for batch size used in the evaluation.
 * @param[in] repe NUmber of repetitions used to smooth the results.
 */
#ifdef PWR
void genOutput_precision(const int nL, int ** model, double** perfMeasures,const int minBatch, const int maxBatch, const int stepBatch,const int repe,counter_t  pwrCounter)
#else
void genOutput_precision(const int nL, int ** model, double** perfMeasures,const int minBatch, const int maxBatch, const int stepBatch,const int repe)
#endif
{
    int l,j,b;
	int id, h,w,c,kh,kw,kn,stride,pad,ho,wo;
	double gflop, gflopTotal;
	double avgPwrSingle,avgPwrDtype, maxPwrSingle,maxPwrDtype, energySingle, energyDtype;
	
    printf("Evaluation results (averaged results of %d repetitions):\n",repe);
    
#ifdef out_csv
  #ifdef PWR
    printf("batch;single_time;single_performance;single_inference_Perfonmance;single_inference_energy;dType_time;dType_performance;dType_inference_Performance;dType_inference_energy\n");
  #else
    printf("batch;single_time;single_performance;single_inference_Perfonmance;dType_time;dType_performance;dType_inference_Performance\n");
  #endif
#endif
    
    #ifdef PWR 
    pm_get_counter_data(&pwrCounter);
#endif
    
    for(b=minBatch,j=0;b<=maxBatch; b+=stepBatch,j++)
    {
		gflopTotal=0;
        for (l = 0;l < nL; l++)
		{
				id = model[l][0];
				h = model[l][1]; w = model[l][2]; c = model[l][3];
				kh = model[l][4]; kw = model[l][5]; kn = model[l][6];
				stride = model[l][7]; pad = model[l][8];
				ho = floor((h - kh + 2 * pad) / stride + 1);
				wo = floor((w - kw + 2 * pad) / stride + 1);
				
				gflop = ( 2.0 * kn*ho*wo*b*kh*kw*c ) /  1.0e9 ;
				gflopTotal+=gflop;
		}
        
#ifdef PWR
        get_energy_stats(pwrCounter,j*2,&avgPwrSingle,&maxPwrSingle, &energySingle);
        get_energy_stats(pwrCounter,j*2+1, &avgPwrDtype, &maxPwrDtype, &energyDtype);
        energySingle/=repe;energyDtype/=repe;
#endif
    
#ifdef out_csv
    #ifdef PWR 
        printf("%d;%.4f;%.3f;%.3f;%4f;%.4f;%.3f;%.3f;%4f\n", b, perfMeasures[0][j],gflopTotal/perfMeasures[0][j],b/perfMeasures[0][j],b/energySingle, perfMeasures[1][j],gflopTotal/perfMeasures[1][j],b/perfMeasures[1][j],b/energyDtype);
    #else
        printf("%d;%.4f;%.3f;%.3f;%.4f;%.3f;%.3f\n", b, perfMeasures[0][j],gflopTotal/perfMeasures[0][j],b/perfMeasures[0][j], perfMeasures[1][j],gflopTotal/perfMeasures[1][j],b/perfMeasures[1][j]);
    #endif
#else
    #ifdef PWR 
        printf("batch[%d],single[T=%.4f,P=%.3f,S=%.3f,E=%4f],half[T=%.4f,P=%.3f, S=%.3f,E=%4f]\n", b, perfMeasures[0][j],gflopTotal/perfMeasures[0][j],b/perfMeasures[0][j],b/energySingle, perfMeasures[1][j],gflopTotal/perfMeasures[1][j],b/perfMeasures[1][j],b/energyDtype);
    #else
		printf("batch[%d],single[T=%.4f,P=%.3f,S=%.3f],half[T=%.4f,P=%.3f, S=%.3f]\n", b, perfMeasures[0][j],gflopTotal/perfMeasures[0][j],b/perfMeasures[0][j], perfMeasures[1][j],gflopTotal/perfMeasures[1][j],b/perfMeasures[1][j]);
    #endif
#endif
    }
}


int main( int argc, char** argv )
{
    char* modelName;    
    int minBatch,
        maxBatch,
        stepBatch,
        repe,
        nL;
    int ** model;
    double** perfMeasures;
    
    #ifdef PWR
    server_t pmlibServer;
    counter_t pwrCounter;
    line_t pwrLines;
    int frequency = 0, aggregate = 1;
    pm_set_server("127.0.0.1",6526, &pmlibServer);
    pm_set_lines("0-11",&pwrLines);
    pm_create_counter("Jetson-TX2",pwrLines,aggregate,frequency,pmlibServer,&pwrCounter);
    #endif
    
    if (argc != 6)
    {
        printf("Performs an evaluation of the convolution layers involved in a DNN inference.\n");
        printf("\tmodel: file containing the network product structure.\n");
        printf("\tminBatch: minimum batch to test the network .\n");
        printf("\tmaxBatch: maximum batch to test the network.\n");
        printf("\tstepBatch: step for the batch performance evaluation.\n");
        printf("\trepe: number of repetitions of the test.\n");
        printf("Usage: %s <model> <minBatch> <maxBatch> <stepBatch> <repe>\n", argv[0]);
        return -1;
    }
    modelName = argv[1];
    minBatch =atoi(argv[2]);  
    maxBatch =atoi(argv[3]);
    stepBatch = atoi(argv[4]);
    repe  =atoi(argv[5]);

    
    nL = loadModel(modelName, &model);
   
#ifdef eval_precision
  #ifdef PWR 
    perfMeasures = evalNet_precision(model, nL, minBatch, maxBatch, stepBatch, repe, &pwrCounter);
    genOutput_precision(nL, model, perfMeasures, minBatch, maxBatch, stepBatch, repe, pwrCounter);
  #else
    perfMeasures = evalNet_precision(model, nL, minBatch, maxBatch, stepBatch, repe);
    genOutput_precision(nL, model, perfMeasures, minBatch, maxBatch, stepBatch, repe);
  #endif
#else
    perfMeasures = evalNet(model, nL, minBatch, maxBatch, stepBatch, repe);
    
    genOutput(nL, model, perfMeasures, minBatch, maxBatch, stepBatch, repe);
#endif
    
    #ifdef PWR 
    pm_finalize_counter(&pwrCounter);
    #endif 
    
    free(perfMeasures);
    free(model);
}


